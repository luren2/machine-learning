{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a36451a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77deabc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size的大小是64\n",
    "batch_size = 64\n",
    "#用Compose组合多个transform操作\n",
    "transform = transforms.Compose([\n",
    "    #ToTensor将图像中的字节转换成tensor;\n",
    "    transforms.ToTensor(),\n",
    "    #Normalize将数据进行标准化，1是均值，2是标准差\n",
    "    transforms.Normalize((0.1307, ),(0.3081, ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48d590a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../dataset/mnist\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7751da915f64230a09e988da0a75801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../dataset/mnist\\MNIST\\raw\\train-images-idx3-ubyte.gz to ../dataset/mnist\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../dataset/mnist\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ea7cf6bf9814f49b5e6a6954cab982c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../dataset/mnist\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ../dataset/mnist\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../dataset/mnist\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cddbcfdfc0cc4037ba46c54743e9dc17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../dataset/mnist\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ../dataset/mnist\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../dataset/mnist\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9aea6b6fcad409980e0d3f50a3d3423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../dataset/mnist\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ../dataset/mnist\\MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#训练数据集的MNIST的数据集的根在mnist文件夹中\n",
    "train_dataset = datasets.MNIST(root='../dataset/mnist',\n",
    "                              #让训练等于真，提取训练集\n",
    "                              train=True,\n",
    "                              #下载等于真，下载数据集\n",
    "                              download=True,\n",
    "                              #transform直接应用上面的transform\n",
    "                              transform=transform) \n",
    "#训练加载器是数据加载器，引入训练数据集\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                         #shuffle为真，将数据打乱\n",
    "                         shuffle=True,\n",
    "                         #batch的大小为前面设定好的大小\n",
    "                         batch_size=batch_size)\n",
    "\n",
    "\n",
    "#测试数据集的MNIST的数据集的根在mnist文件夹中\n",
    "test_dataset = datasets.MNIST(root='../dataset/mnist/',\n",
    "                             #训练为假，测试为真\n",
    "                             train=False,\n",
    "                             #下载为真，就是下载\n",
    "                             download=True,\n",
    "                             #transform直接应用上面的transform\n",
    "                             transform=transform)\n",
    "#测试加载器是数据加载器，引入测试数据集\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                        #shuffle为假，不将数据打乱\n",
    "                        shuffle=False,\n",
    "                        #batch的大小为前面设定好的大小 \n",
    "                        batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa10fe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#设Net为一个类，继承自Module模块\n",
    "class Net(torch.nn.Module):\n",
    "    #自身初始化\n",
    "    def __init__(self):\n",
    "        #调用父类初始化器\n",
    "        super(Net,self).__init__()\n",
    "        #线性变换将784变成10\n",
    "        self.l1 = torch.nn.Linear(784,512)\n",
    "        self.l2 = torch.nn.Linear(512,256)\n",
    "        self.l3 = torch.nn.Linear(256,128)\n",
    "        self.l4 = torch.nn.Linear(128,64)\n",
    "        self.l5 = torch.nn.Linear(64,10)\n",
    "    #定义自身前馈计算\n",
    "    def forward(self,x):\n",
    "        #用view改变x的形状，列为784，行自动计算得到\n",
    "        x = x.view(-1,784)\n",
    "        #用relu激活自身的线性函数\n",
    "        x = torch.relu(self.l1(x))\n",
    "        x = torch.relu(self.l2(x))\n",
    "        x = torch.relu(self.l3(x))\n",
    "        x = torch.relu(self.l4(x))\n",
    "        #返回第五层，不激活最后一层,要接入softmax\n",
    "        return self.l5(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc83848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27574427",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.01, momentum = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "237c3457",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义训练过程，epoch是循环次数\n",
    "def train(epoch):\n",
    "    #设初始损失值是0\n",
    "    running_loss = 0.0\n",
    "    #batch_idx表示进行多少次的batch的迭代，data是数据，用列举的方法将train_loader的数据提取出来，从0开始\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        inputs, target = data\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(net(inputs), target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if batch_idx % 300 == 299:\n",
    "            print('{},{} loss:{:.6f}'.format(epoch + 1,batch_idx + 1,running_loss / 300))\n",
    "            #将损失归零\n",
    "            running_loss = 0.0\n",
    "            print('{},{} loss:{:.6f}'.format(epoch + 1,batch_idx + 1,running_loss / 2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "894c6fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义test模块\n",
    "def test():\n",
    "    #正确的数量初始为0\n",
    "    correct = 0\n",
    "    #总数为0\n",
    "    total = 0\n",
    "    #用with方式让torch不计算梯度\n",
    "    with torch.no_grad():\n",
    "        #for循环data在测试加载器中\n",
    "        for data in test_loader:\n",
    "            #测试集里面的images相当于输入，输入和标签送到数据里面\n",
    "            images,labels = data\n",
    "            #将输入代入模型，求输出\n",
    "            outputs = net(images)\n",
    "            #用torch中的max函数，沿着输出的数据的维度为1方式，找到最大值和最大值的下标，\n",
    "            #_是最大值，predicted是最大值的下标\n",
    "            _, predicted = torch.max(outputs.data,dim=1)\n",
    "            #总数等于标签的size取第0个元素相加求得总数\n",
    "            total += labels.size(0)\n",
    "            #正确是预测和标签相等标量求和\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    #输出%d代表整数，%%代表%，%格式化输出得连接符号，正确除总数乘100\n",
    "    print('Accuracy on test set: {}%'.format(100 * correct / total))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d00700d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,300 loss:0.014279\n",
      "1,300 loss:0.000000\n",
      "1,600 loss:0.018465\n",
      "1,600 loss:0.000000\n",
      "1,900 loss:0.020775\n",
      "1,900 loss:0.000000\n",
      "Accuracy on test set: 97.82%\n",
      "2,300 loss:0.012600\n",
      "2,300 loss:0.000000\n",
      "2,600 loss:0.015676\n",
      "2,600 loss:0.000000\n",
      "2,900 loss:0.013459\n",
      "2,900 loss:0.000000\n",
      "Accuracy on test set: 97.86%\n",
      "3,300 loss:0.009450\n",
      "3,300 loss:0.000000\n",
      "3,600 loss:0.012237\n",
      "3,600 loss:0.000000\n",
      "3,900 loss:0.012252\n",
      "3,900 loss:0.000000\n",
      "Accuracy on test set: 97.82%\n",
      "4,300 loss:0.007301\n",
      "4,300 loss:0.000000\n",
      "4,600 loss:0.007666\n",
      "4,600 loss:0.000000\n",
      "4,900 loss:0.008440\n",
      "4,900 loss:0.000000\n",
      "Accuracy on test set: 97.95%\n",
      "5,300 loss:0.004747\n",
      "5,300 loss:0.000000\n",
      "5,600 loss:0.007081\n",
      "5,600 loss:0.000000\n",
      "5,900 loss:0.006555\n",
      "5,900 loss:0.000000\n",
      "Accuracy on test set: 97.96%\n",
      "6,300 loss:0.004463\n",
      "6,300 loss:0.000000\n",
      "6,600 loss:0.003598\n",
      "6,600 loss:0.000000\n",
      "6,900 loss:0.004775\n",
      "6,900 loss:0.000000\n",
      "Accuracy on test set: 97.93%\n",
      "7,300 loss:0.003543\n",
      "7,300 loss:0.000000\n",
      "7,600 loss:0.003518\n",
      "7,600 loss:0.000000\n",
      "7,900 loss:0.003276\n",
      "7,900 loss:0.000000\n",
      "Accuracy on test set: 97.87%\n",
      "8,300 loss:0.002659\n",
      "8,300 loss:0.000000\n",
      "8,600 loss:0.002848\n",
      "8,600 loss:0.000000\n",
      "8,900 loss:0.002199\n",
      "8,900 loss:0.000000\n",
      "Accuracy on test set: 97.98%\n",
      "9,300 loss:0.001743\n",
      "9,300 loss:0.000000\n",
      "9,600 loss:0.001621\n",
      "9,600 loss:0.000000\n",
      "9,900 loss:0.002276\n",
      "9,900 loss:0.000000\n",
      "Accuracy on test set: 97.75%\n",
      "10,300 loss:0.002469\n",
      "10,300 loss:0.000000\n",
      "10,600 loss:0.001905\n",
      "10,600 loss:0.000000\n",
      "10,900 loss:0.001580\n",
      "10,900 loss:0.000000\n",
      "Accuracy on test set: 97.9%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10): \n",
    "    #训练\n",
    "    train(epoch)\n",
    "    #测试\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541a4b57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
